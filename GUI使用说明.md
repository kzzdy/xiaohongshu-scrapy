# 小红书爬虫GUI使用说明

## 📖 简介

本项目提供了一个友好的图形用户界面（GUI），让你无需编写代码即可使用所有爬虫功能。

## 🚀 快速开始

### 1. 环境准备

确保已安装：
- Python 3.7 或更高版本
- 所有依赖包（运行 `pip install -r requirements.txt`）

### 2. 配置Cookie

**方法一：使用GUI配置（推荐）**

1. 启动GUI后，在"配置"页面点击"创建示例.env"
2. 点击"打开.env文件"
3. 将你的Cookie粘贴到 `COOKIES=` 后面
4. 保存文件
5. 点击"重新加载配置"

**方法二：手动创建.env文件**

在项目根目录创建 `.env` 文件，内容如下：

```env
COOKIES=your_cookies_here
RATE_LIMIT=3.0
RETRY_TIMES=3
TIMEOUT=30
OUTPUT_DIR=datas
LOG_LEVEL=INFO
```

### 3. 启动GUI

**Windows用户：**
- 双击 `启动GUI.bat` 文件

**所有平台：**
```bash
python gui_main.py
```

## 🎯 功能说明

### 推荐工作流程

```
┌─────────────────────────────────────────────────────────────┐
│ 第一步：搜索爬取（获取笔记列表）                              │
├─────────────────────────────────────────────────────────────┤
│ • 输入关键词（如：重庆美食、用户昵称）                        │
│ • 设置数量（建议10-50）                                      │
│ • 选择排序方式                                               │
│ • 点击"开始搜索（仅保存JSON）"                               │
│ ↓                                                           │
│ 保存到：datas/json_datas/search_关键词_时间.json             │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ 第二步：JSON管理器（提取笔记链接）                            │
├─────────────────────────────────────────────────────────────┤
│ • 点击"刷新列表"                                             │
│ • 选择JSON文件                                               │
│ • 查看笔记列表（标题+链接）                                  │
│ • 点击"复制所有链接"                                         │
│ ↓                                                           │
│ 链接已复制到剪贴板                                           │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ 第三步：笔记爬取（下载完整内容）                              │
├─────────────────────────────────────────────────────────────┤
│ • 粘贴链接（Ctrl+V）                                         │
│ • 选择保存格式（Excel/JSON/CSV）                             │
│ • 勾选"下载图片/视频"                                        │
│ • 点击"开始爬取"                                             │
│ ↓                                                           │
│ 保存到：datas/excel_datas/ 和 datas/media_datas/            │
└─────────────────────────────────────────────────────────────┘
```

### ⚙️ 配置页面

这是第一个页面，用于管理配置。

**功能按钮：**
- **重新加载配置** - 从.env文件重新读取配置
- **打开.env文件** - 直接打开.env文件进行编辑
- **创建示例.env** - 创建一个包含所有配置项的示例文件

**配置项说明：**

| 配置项 | 说明 | 默认值 | 必填 |
|--------|------|--------|------|
| COOKIES | 小红书登录Cookie | - | ✅ |
| RATE_LIMIT | 请求速率（请求/秒） | 3.0 | ❌ |
| RETRY_TIMES | 失败重试次数 | 3 | ❌ |
| TIMEOUT | 请求超时时间（秒） | 30 | ❌ |
| OUTPUT_DIR | 输出目录 | datas | ❌ |
| LOG_LEVEL | 日志级别 | INFO | ❌ |
| ENABLE_RESUME | 启用断点续传 | true | ❌ |
| DOWNLOAD_MEDIA | 下载媒体文件 | true | ❌ |

### 🔍 搜索爬取页面（第一步）

搜索关键词，获取笔记列表并保存为JSON格式。

**功能说明：**
- 搜索爬取用于获取笔记列表（保存为JSON），不下载图片/视频
- 工作流程：搜索 → 保存JSON → JSON管理器提取链接 → 笔记爬取下载完整内容

**使用步骤：**

1. 输入搜索关键词
   ```
   重庆美食
   ```
   提示：可以输入用户昵称、话题等

2. 设置爬取数量
   - 建议：10-50（避免触发风控）
   - 范围：1-1000

3. 选择排序方式：
   - **综合** - 综合排序（推荐）
   - **最新** - 按发布时间排序
   - **最热** - 按热度排序

4. 点击"开始搜索（仅保存JSON）"按钮

**输出位置：**
- JSON文件：`datas/json_datas/search_关键词_时间.json`

**下一步：**
切换到【JSON管理器】标签页，提取笔记链接

### 📁 JSON管理器页面（第二步）

查看搜索结果，提取笔记链接。

**使用步骤：**

1. 点击"刷新列表"按钮
2. 从下拉列表中选择JSON文件
3. 右侧显示笔记列表（标题+链接）
4. 点击"复制所有链接"按钮
5. 看到提示："已复制 X 个链接"

**功能按钮：**
- **刷新列表** - 重新扫描json_datas目录
- **复制所有链接** - 复制所有笔记链接到剪贴板
- **打开目录** - 打开json_datas文件夹

**下一步：**
切换到【笔记爬取】标签页，粘贴链接并下载完整内容

### 📝 笔记爬取页面（第三步）

下载笔记的完��内容（图片/视频）。

**使用步骤：**

1. 在文本框中粘贴笔记URL（Ctrl+V）
   - 可以从JSON管理器复制
   - 也可以手动输入
   ```
   https://www.xiaohongshu.com/explore/64356527000000001303282b
   https://www.xiaohongshu.com/explore/63d625f8000000001d01042c
   ```

2. 选择保存格式：
   - **JSON** - 结构化数据，适合程序处理
   - **CSV** - 表格格式，可用Excel打开
   - **Excel** - Excel文件，包含完整信息

3. 勾选"下载图片/视频"
   - 勾选：下载笔记中的所有图片和视频
   - 不勾选：只保存笔记的文本信息

4. 点击"开始爬取"按钮

**输出位置：**
- 数据文件：`datas/excel_datas/`
- 媒体文件：`datas/media_datas/笔记标题_笔记ID/`

### 📋 日志页面

实时显示爬虫运行日志。

**日志颜色：**
- **黑色** - 普通信息
- **橙色** - 警告信息
- **红色** - 错误信息

**功能按钮：**
- **清空日志** - 清除当前显示的所有日志
- **保存日志** - 将日志保存到文本文件

**日志内容：**
- 配置加载状态
- 爬取进度
- 成功/失败信息
- 错误详情

## 📁 输出文件结构

```
datas/
├── notes/                    # 笔记数据
│   ├── note_123.json        # 笔记详情
│   ├── note_456.json
│   └── media/               # 笔记媒体文件
│       ├── note_123/
│       │   ├── image_0.jpg
│       │   └── video.mp4
│       └── note_456/
│           └── image_0.jpg
│
├── users/                    # 用户数据
│   ├── user_789/
│   │   ├── profile.json     # 用户资料
│   │   ├── notes.json       # 笔记列表
│   │   └── media/           # 媒体文件
│   └── user_101/
│
├── search/                   # 搜索结果
│   ├── 美食/
│   │   ├── results.json     # 搜索结果
│   │   └── media/           # 媒体文件
│   └── 旅游/
│
└── .progress.json           # 进度文件（断点续传）
```

## 🔧 高级功能

### 断点续传

启用后，程序会记录已下载的笔记，重新运行时自动跳过。

**配置方法：**
在.env文件中设置：
```env
ENABLE_RESUME=true
```

**工作原理：**
- 程序会在 `datas/.progress.json` 中记录已完成的笔记ID
- 重新运行时，会自动跳过已记录的笔记
- 可以手动删除进度文件来重新开始

### 速率限制

控制请求频率，避免被平台限制。

**配置方法：**
```env
RATE_LIMIT=3.0  # 每秒3个请求
```

**建议值：**
- 保守：2.0-3.0 请求/秒
- 正常：3.0-5.0 请求/秒
- 激进：5.0-10.0 请求/秒（可能被限制）

### 并发下载

同时下载多个媒体文件，提高效率。

**配置方法：**
```env
MAX_CONCURRENT_DOWNLOADS=3
```

**建议值：**
- 网速慢：1-2
- 网速正常：3-5
- 网速快：5-10

## ❓ 常见问题

### 1. 如何获取Cookie？

**详细步骤：**

1. 打开小红书网页版：https://www.xiaohongshu.com
2. 登录你的账号
3. 按 `F12` 打开开发者工具
4. 点击顶部的 `Network`（网络）标签
5. 点击 `Fetch/XHR` 筛选
6. 刷新页面（按 `F5`）
7. 点击任意一个请求
8. 在右侧找到 `Request Headers`（请求头）
9. 找到 `Cookie:` 字段
10. 复制整个Cookie值（从 `Cookie:` 后面开始）
11. 粘贴到.env文件的 `COOKIES=` 后面

**注意：**
- Cookie必须在登录状态下获取
- Cookie会过期，过期后需要重新获取
- 不要分享你的Cookie给他人

### 2. 提示"配置加载失败"

**可能原因：**
- .env文件不存在 → 点击"创建示例.env"
- Cookie未填写 → 检查COOKIES配置项
- Cookie格式错误 → 重新复制完整的Cookie
- Cookie已过期 → 重新获取Cookie

**解决方法：**
1. 查看日志页面的详细错误信息
2. 确认.env文件存在且格式正确
3. 重新获取Cookie并填入
4. 点击"重新加载配置"

### 3. 爬取失败或没有数据

**可能原因：**
- Cookie无效或过期
- 网络连接问题
- 请求速率过快被限制
- URL格式错误

**解决方法：**
1. 检查Cookie是否有效（重新获取）
2. 检查网络连接
3. 降低速率限制（增大RATE_LIMIT的值）
4. 确认URL格式正确
5. 查看日志页面的错误详情

### 4. 程序卡住不动

**可能原因：**
- 正在下载大文件
- 网络速度慢
- 程序确实卡住了

**解决方法：**
1. 查看日志页面，确认是否在正常运行
2. 等待一段时间（下载大文件需要时间）
3. 如果确实卡住，关闭程序重新启动
4. 启用断点续传，可以继续之前的进度

### 5. 如何提高爬取速度？

**方法：**
1. 适当提高速率限制（但不要太高）
   ```env
   RATE_LIMIT=5.0
   ```

2. 增加并发下载数
   ```env
   MAX_CONCURRENT_DOWNLOADS=5
   ```

3. 如果不需要媒体文件，取消"下载图片/视频"选项

4. 使用更快的网络连接

**注意：**
- 速率太高可能被平台限制
- 建议逐步调整，找到最佳值

### 6. 下载的文件在哪里？

**默认位置：**
- 项目根目录的 `datas` 文件夹

**自定义位置：**
在.env文件中修改：
```env
OUTPUT_DIR=D:/my_data
```

### 7. 如何批量爬取多个用户？

**方法一：使用笔记爬取**
1. 先获取所有用户的笔记URL
2. 在笔记爬取页面批量输入

**方法二：使用Python脚本**
```python
from src.core.config import ConfigManager
from src.spider.user_spider import UserSpider

config = ConfigManager().load_config()
spider = UserSpider(config)

user_urls = [
    "https://www.xiaohongshu.com/user/profile/...",
    "https://www.xiaohongshu.com/user/profile/...",
]

for url in user_urls:
    spider.crawl_user_notes(url)
```

### 8. 如何导出为Excel？

**方法：**
1. 在保存格式中选择"Excel"
2. 爬取完成后，在输出目录找到 `.xlsx` 文件
3. 使用Excel或WPS打开

**Excel内容：**
- 笔记标题
- 作者信息
- 发布时间
- 点赞/收藏/评论数
- 笔记内容
- 图片/视频URL

## 🎨 界面截图

### 配置页面
![配置页面](docs/images/gui_config.png)

### 笔记爬取页面
![笔记爬取](docs/images/gui_note.png)

### 搜索页面
![搜索页面](docs/images/gui_search.png)

### 日志页面
![日志页面](docs/images/gui_log.png)

## 📝 使用技巧

### 1. 批量操作

**笔记爬取：**
- 可以一次输入多个URL（每行一个）
- 程序会按顺序依次爬取
- 失败的会跳过，不影响其他笔记

**用户爬取：**
- 一次只能爬取一个用户
- 如需批量，可以使用Python脚本

### 2. 数据管理

**定期清理：**
- 定期清理不需要的数据
- 删除 `.progress.json` 可以重新开始

**备份数据：**
- 定期备份 `datas` 文件夹
- 重要数据建议多处备份

### 3. 性能优化

**网络优化：**
- 使用稳定的网络连接
- 必要时使用代理

**配置优化：**
- 根据网络情况调整速率限制
- 根据需求选择是否下载媒体文件

## 🆘 获取帮助

如果遇到问题：

1. **查看日志** - 日志页面有详细的错误信息
2. **查看文档** - 阅读本文档和项目README
3. **检查配置** - 确认.env文件配置正确
4. **重新获取Cookie** - Cookie可能已过期
5. **提交Issue** - 在GitHub上提交问题

## 📄 许可证

本项目仅供学习交流使用，请勿用于商业用途。

## 🙏 致谢

感谢所有贡献者和使用者的支持！

---

**祝你使用愉快！** 🎉
